ggtitle(paste("PCA based on", title, sep=" "))+
theme(plot.title = element_text(hjust = 0.5)) +
scale_color_manual(values=colores)
}
k <- nrow(enc_output_cifra)
scale = FALSE
plotPCA3(datos = enc_output_cifra[1:k,],
labels = rep("",k),
factor = as.factor(y.onehot[1:k]),
scale = scale,
title = paste ("last encode layer.", "# Samples:", k),
colores = brewer.pal(n = 10, name = "RdBu"))
plotPCA3 <- function (datos, labels, factor,title,scale,colores, size = 2, glineas = 0.25) {
data <- prcomp(datos , scale = scale)
dataDf <- data.frame(data$x)
Group <- factor
loads <- round(data$sdev^2/sum(data$sdev^2)*100,1)
# the graphic
p1 <- ggplot(dataDf,aes(x=PC1, y=PC2)) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = Group), alpha = 0.55, size = 1.2) +
coord_cartesian(xlim = c(min(data$x[,1])-5,max(data$x[,1])+5)) +
scale_fill_discrete(name = "")
# the graphic with ggrepel
p1 + geom_text_repel(aes(y = PC2 + 0.25, label = labels),segment.size = 0.25, size = size) +
labs(x = c(paste("PC1",loads[1],"%")),y=c(paste("PC2",loads[2],"%"))) +
ggtitle(paste("PCA based on", title, sep=" "))+
theme(plot.title = element_text(hjust = 0.5)) +
scale_color_manual(values=colores)
}
k <- nrow(enc_output_cifra)
scale = FALSE
plotPCA3(datos = enc_output_cifra[1:k,],
labels = rep("",k),
factor = as.factor(y.onehot[1:k]),
scale = scale,
title = paste ("last encode layer.", "# Samples:", k),
colores = brewer.pal(n = 10, name = "RdBu"))
plotPCA3 <- function (datos, labels, factor,title,scale,colores, size = 2, glineas = 0.25) {
data <- prcomp(datos , scale = scale)
dataDf <- data.frame(data$x)
Group <- factor
loads <- round(data$sdev^2/sum(data$sdev^2)*100,1)
# the graphic
p1 <- ggplot(dataDf,aes(x=PC1, y=PC2)) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = Group), alpha = 0.55, size = 1) +
coord_cartesian(xlim = c(min(data$x[,1])-5,max(data$x[,1])+5)) +
scale_fill_discrete(name = "")
# the graphic with ggrepel
p1 + geom_text_repel(aes(y = PC2 + 0.25, label = labels),segment.size = 0.25, size = size) +
labs(x = c(paste("PC1",loads[1],"%")),y=c(paste("PC2",loads[2],"%"))) +
ggtitle(paste("PCA based on", title, sep=" "))+
theme(plot.title = element_text(hjust = 0.5)) +
scale_color_manual(values=colores)
}
k <- nrow(enc_output_cifra)
scale = FALSE
plotPCA3(datos = enc_output_cifra[1:k,],
labels = rep("",k),
factor = as.factor(y.onehot[1:k]),
scale = scale,
title = paste ("last encode layer.", "# Samples:", k),
colores = brewer.pal(n = 10, name = "RdBu"))
tsne_model_1 = Rtsne(enc_output_cifra[1:k,],
check_duplicates=FALSE,
pca=TRUE,
perplexity=30,
theta=0.5,
dims=2)
## getting the two dimension matrix
d_tsne_1 = as.data.frame(tsne_model_1$Y)
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
as.factor(y.onehot[1:k])
as.factor(y.onehot[1:k])+
1
as.factor(y.onehot[1:k])
y.onehot[1:k]
y.onehot[1:k]+1
tsne_model_1 = Rtsne(enc_output_cifra[1:k,],
check_duplicates=FALSE,
pca=TRUE,
perplexity=30,
theta=0.5,
dims=2)
## getting the two dimension matrix
d_tsne_1 = as.data.frame(tsne_model_1$Y)
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=y.onehot[1:k]+1)) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]+1))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=y.onehot[1:k]+1)) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=c(1,2,3))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank()) +
scale_colour_brewer(palette = "RdBu") # create a custom color scale
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6))) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank())
?ggtitle
?guide_legend
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6),title"")) +
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6),title="dd")) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank())
## plotting the results without clustering
ggplot(d_tsne_1, aes(x=V1, y=V2, colour=as.factor(y.onehot[1:k]))) +
geom_point(size=0.40) +
guides(colour=guide_legend(override.aes=list(size=6),title="Group")) +
xlab("") + ylab("") +
ggtitle("t-SNE") +
theme_light(base_size=20) +
theme(axis.text.x=element_blank(),
axis.text.y=element_blank())
knitr::opts_chunk$set(echo = TRUE)
classify <- function(path) {
#upload image
image <- readImage(path)
image.grey <- rgb_2gray(image)
image.resized <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear')
#transform into the correcto input dimension for the model
new.image <- array(image.resized, dim = c(1, 32, 32, 1))
#Load the model generated previously
cnn.model <- load_model_hdf5("cnn_model.h5")
#Prediction of the image class
pred <- cnn.model %>% predict(new.image)
#display outpout
if (which.max(pred) == 1) {
print("Airplane")
} else if (which.max(pred) == 2) {
print("Motorbike")
} else {
print("Face")
}
}
library(OpenImageR)
library(caret)
library(keras)
library(Xmisc)
library(ggplot2)
library(RColorBrewer)
library(ggrepel)
library(Rtsne)
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
init <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(init,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i)[1:30])){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
counter <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
for (i in file.path){
image <- readImage(i)
image.grey <- rgb_2gray(image)
image.reshaped <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[counter, ] <- image.vector
counter <- counter + 1
}
counter <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
for (i in file.path){
image <- readImage(i)
if (is.na(dim(image)[3]) == FALSE){
image.grey <- rgb_2gray(image)}
else{
image.grey <- image
}
image.reshaped <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[counter, ] <- image.vector
counter <- counter + 1
}
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
init <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(init,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i)[1:30])){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
m <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
for (i in file.path){
image <- readImage(i)
if (is.na(dim(image)[3]) == FALSE){
image.grey <- rgb_2gray(image)}
else{
image.grey <- image
}
image.reshaped <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[m, ] <- image.vector
m <- m + 1
}
# Normalization of the image information for the NN
normalizer <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
x_train <- as.data.frame(lapply(as.data.frame(output), normalizer))
output.hog <- matrix(0, nrow = length(file.path), ncol = 81)
counter.hog <- 1
for (a in file.path){
image.hog <- HOG(readImage(file.path(a)), cells = 3, orientations = 9)
output.hog[counter.hog, ] <- image.hog
counter.hog <- counter.hog + 1
}
library(OpenImageR)
library(caret)
library(keras)
library(Xmisc)
library(ggplot2)
library(RColorBrewer)
library(ggrepel)
library(Rtsne)
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
init <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(init,i, sep = ""))
}
#Import images
names <- c('airplanes', 'Motorbikes', 'Faces')
root <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(root,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i))){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
path.filtered <- c()
for (i in file.path){
if (endswith(i, '.jpg', ignore.case = FALSE) == TRUE){path.filtered <- c(path.filtered, i)}
}
counter <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
#convert to grey scale with size 32 x 32 as a vector
for (i in file.path){
image <- readImage(i)
if (is.na(dim(image)[3]) == FALSE){image.grey <- rgb_2gray(image)}
else{image.grey <- image}
image.reshaped <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[counter, ] <- image.vector
counter <- counter + 1
}
#normalize the data
x_train <- as.data.frame(lapply(as.data.frame(output), normalizer))
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
rooh <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(root,i, sep = ""))
}
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
root <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(root,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i)[1:30])){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
file.path <- c()
for (i in path){
for (files in (list.files(i)[1:50])){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
m <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
for (i in file.path){
image <- readImage(i)
if (is.na(dim(image)[3]) == FALSE){
image.grey <- rgb_2gray(image)}
else{
image.grey <- image
}
image.reshaped <- resizeImage(image.grey, width = 32, height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[m, ] <- image.vector
m <- m + 1
}
# Normalization of the image information for the NN
normalizer <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
x_train <- as.data.frame(lapply(as.data.frame(output), normalizer))
o.hog <- matrix(0, nrow = length(file.path), ncol = 81)
counter.hog <- 1
for (a in file.path){
image.hog <- HOG(readImage(file.path(a)), cells = 3, orientations = 9)
o.hog[counter.hog, ] <- image.hog
counter.hog <- counter.hog + 1
}
names <- c('airplanes', 'Motorbikes', 'Faces')
root <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(root,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i))){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
path.filtered <- c()
for (i in file.path){
if (endswith(i, '.jpg', ignore.case = FALSE) == TRUE){path.filtered <- c(path.filtered, i)}
}
path.filtered
library(OpenImageR)
library(caret)
library(keras)
library(Xmisc)
library(ggplot2)
library(RColorBrewer)
library(ggrepel)
library(Rtsne)
names <- c("bass", "crocodile", "dolphin", "elephant", "llama")
root <- "101_ObjectCategories/"
path <- c()
for (i in names){
path <- c(path, paste(root,i, sep = ""))
}
file.path <- c()
for (i in path){
for (files in (list.files(i)[1:50])){
file.path <- c(file.path, paste(i, files, sep = "/"))
}
}
m <-  1
output <- matrix(0, nrow = length(file.path), ncol = 1024)
for (i in file.path){
image <- readImage(i)
if (is.na(dim(image)[3]) == FALSE){
image.grey <- rgb_2gray(image)}
else{
image.grey <- image
}
image.reshaped <- resizeImage(image.grey, width = 32,
height = 32, method = 'bilinear') #reshape
image.vector <- as.vector(image.reshaped) # as 1024 vector
output[m, ] <- image.vector
m <- m + 1
}
# Normalization of the image information for the NN
normalizer <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
x_train <- as.data.frame(lapply(as.data.frame(output), normalizer))
o.hog <- matrix(0, nrow = length(file.path), ncol = 81)
m <- 1
for (a in file.path){
image.hog <- HOG(readImage(file.path(a)), cells = 3, orientations = 9)
o.hog[m, ] <- image.hog
m <- m + 1
}
y.res <- array(c(rep(c(0,1,2,3,4), each = 30))) %>%
array(dim = c(length(file.path))) %>%
to_categorical(num_classes = 5)
res.grid <- data.frame()
m <- 1
for (firstlayer in c(25, 80, 100)){
for (secondlayer in c(10, 50, 70)){
start_time <- Sys.time()
model <- keras_model_sequential()
model %>%
layer_dense(units = dim(x_train)[1], activation = 'relu',
input_shape = dim(x_train)[2]) %>%
layer_dense(units = firstlayer, activation = 'relu') %>%
layer_dense(units = secondlayer, activation = 'relu') %>%
layer_dense(units = 5, activation = 'softmax') %>%
compile(
optimizer = 'rmsprop',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
out <- model %>% fit(as.matrix(x_train), y.res, epochs = 100)
end_time <- Sys.time()
res.grid[c, 1] <- firstlayer
res.grid[c, 2] <- secondlayer
res.grid[c, 3] <- out$metrics$acc[length(out$metrics$acc)]
res.grid[c, 4] <- end_time - start_time
m <- m + 1
}
}
res.grid[c, 1] <- firstlayer
res.grid <- data.frame()
m <- 1
res.grid[c, 1] <- firstlayer
res.grid
firstlayer
res.grid[c, 1]
res.grid[c, 1] <- firstlayer
firstlayer
res.grid[c, 1] <- firstlayer
res.grid[1, 1] <- firstlayer
res.grid <- data.frame()
m <- 1
for (firstlayer in c(25, 80, 100)){
for (secondlayer in c(10, 50, 70)){
start_time <- Sys.time()
model <- keras_model_sequential()
model %>%
layer_dense(units = dim(x_train)[1], activation = 'relu',
input_shape = dim(x_train)[2]) %>%
layer_dense(units = firstlayer, activation = 'relu') %>%
layer_dense(units = secondlayer, activation = 'relu') %>%
layer_dense(units = 5, activation = 'softmax') %>%
compile(
optimizer = 'rmsprop',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
out <- model %>% fit(as.matrix(x_train), y.res, epochs = 100)
end_time <- Sys.time()
res.grid[m, 1] <- firstlayer
res.grid[m, 2] <- secondlayer
res.grid[m, 3] <- out$metrics$acc[length(out$metrics$acc)]
res.grid[m, 4] <- end_time - start_time
m <- m + 1
}
}
colnames(res.grid) <- c("First-Layer","Second-Layer","Final-Accuracy","CPU-Time")
